package org.dice_research.ldcbench.benchmark;

import java.io.BufferedInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.util.Arrays;
import java.util.concurrent.Future;

import org.apache.commons.lang3.ArrayUtils;
import org.apache.jena.rdf.model.Model;
import org.apache.jena.rdf.model.ModelFactory;
import org.apache.jena.rdf.model.Resource;
import org.dice_research.ldcbench.ApiConstants;
import org.dice_research.ldcbench.Constants;
import org.dice_research.ldcbench.benchmark.cloud.NodeManager;
import org.dice_research.ldcbench.vocab.LDCBench;
import org.hobbit.utils.rdf.RdfHelper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class LemmingBasedBenchmarkController extends BenchmarkController {

    private static final Logger LOGGER = LoggerFactory.getLogger(LemmingBasedBenchmarkController.class);

    private static final String DATA_GEN_CLASS_NAME = "org.dice_research.ldcbench.benchmark.FileBasedRDFGraphGenerator";
    private static final String DATA_DIRECTORY = "/usr/src/app/data";
    private static final String LOCAL_TESTING_DATA_DIRECTORY = "../ldcbench.lemming/data";
    public static final String LEMMING_DOCKER_IMAGE = "git.project-hobbit.eu:4567/ldcbench/ldcbench/ldcbench.lemming";

    /**
     * Only 20% of the triples should be used for evaluation.
     */
    private static final double EVALUATION_RATIO = 0.2;

    /**
     * The ID of the file that will be used by the next data generator created.
     */
    private int fileId = 0;
    /**
     * The files generated by Lemming that will be used by the data generators.
     */
    private File files[];

    @Override
    public void postAbstractInit() throws Exception {
        // Read dataset name
        Resource dataset = RdfHelper.getObjectResource(benchmarkParamModel, null, LDCBench.lemmingDataset);
        if (dataset == null) {
            LOGGER.error(
                    "The lemming dataset is missing! I will throw an exception. Before, I will dump the parameter model: {}",
                    benchmarkParamModel.toString());
            throw new IllegalArgumentException("The lemming dataset is missing!");
        }
        Model benchmarkModel = readBenchmarkModel();
        if (benchmarkModel == null) {
            throw new IllegalArgumentException("Couldn't load the benchmark.ttl model of this benchmark. Aborting.");
        }
        String directory = RdfHelper.getStringValue(benchmarkModel, dataset, LDCBench.lemmingDatasetDirectory);
        if (directory == null) {
            // Check the model of this experiment (helps a lot when testing locally)
            directory = RdfHelper.getStringValue(benchmarkParamModel, dataset, LDCBench.lemmingDatasetDirectory);
            if (directory == null) {
            LOGGER.error(
                    "The directory of the lemming dataset is missing! I will throw an exception. Before, I will dump the benchmark model: {}",
                    benchmarkModel.toString());
            throw new IllegalArgumentException("The directory of the lemming dataset is missing!");
        }}
        // Get all files of a dataset
        String absolutDataDir = dockerized ? DATA_DIRECTORY
                : (new File(LOCAL_TESTING_DATA_DIRECTORY)).getAbsolutePath();
        File dataDir = new File(absolutDataDir + File.separator + directory);
        if (!dataDir.exists() || !dataDir.isDirectory()) {
            throw new IllegalArgumentException(
                    "The given dataset directory (" + dataDir.getAbsolutePath() + ") does not exist!");
        }
        files = dataDir.listFiles();
        if (files.length == 0) {
            throw new IllegalArgumentException(
                    "The given dataset directory (" + dataDir.getAbsolutePath() + ") does not contain any files!");
        }
    }

    protected Model readBenchmarkModel() throws IOException {
        Model model = ModelFactory.createDefaultModel();
        try (InputStream is = this.dockerized ? this.getClass().getResourceAsStream("/benchmark.ttl")
                : (new BufferedInputStream(new FileInputStream("../benchmark.ttl")))) {
            model.read(is, "", "TURTLE");
        }
        return model;
    }

    protected void createDataGenerator(NodeManager nodeManager, String[] envVariables) {
        String[] variables;
        String imageName = nodeManager.getDataGeneratorImageName();
        if (Constants.DATAGEN_IMAGE_NAME.equals(imageName)) {
            imageName = LEMMING_DOCKER_IMAGE;
            variables = envVariables != null ? Arrays.copyOf(envVariables, envVariables.length + 4) : new String[4];
            variables[variables.length - 4] = "CLASS=" + DATA_GEN_CLASS_NAME;
            variables[variables.length - 3] = FileBasedRDFGraphGenerator.RDF_FILE_LOCATION_KEY + "=" + files[fileId];
            variables[variables.length - 2] = FileBasedRDFGraphGenerator.RDF_FILE_LANG_KEY + "=TTL";
            ++fileId;
            // If we have reached the end of the files, start again
            if (fileId == files.length) {
                fileId = 0;
            }
        } else {
            variables = envVariables != null ? Arrays.copyOf(envVariables, envVariables.length + 1) : new String[1];
        }
        variables[variables.length - 1] = org.hobbit.core.Constants.GENERATOR_ID_KEY + "="
                + (dataGenContainers.size() + 1);
        Future<String> container = createContainerAsync(imageName, org.hobbit.core.Constants.CONTAINER_TYPE_BENCHMARK,
                variables);
        dataGenContainers.add(container);
    }

    @Override
    protected void createEvaluationModule(String evalModuleImageName, String[] envVariables) {
        super.createEvaluationModule(evalModuleImageName,
                ArrayUtils.add(envVariables, ApiConstants.ENV_EVALUATION_RATIO_KEY + "=" + EVALUATION_RATIO));
    }

}
